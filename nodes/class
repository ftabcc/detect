#!/usr/bin/env python3


import rospy
from sensor_msgs.msg import Image
import cv2  # OpenCV 라이브러리 import
import sys  # sys 모듈 import
import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.
import math  # math 모듈 import
from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Twist

class CameraSubscriber:
    def __init__(self, camera_topic):
        # Initialize the ROS node
        rospy.init_node('camera_subscriber_node', anonymous=True)
        
        self.cvBridge = CvBridge()

        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        self.mp_hands = mp.solutions.hands  # 손 인식을 위한 객체
        self.hands = self.mp_hands.Hands()  # 손 인식 객체 생성

        # Define the topic to subscribe to
        self.camera_topic = camera_topic

        self.twist = Twist()
        self.pub = rospy.Publisher('cmd_vel', Twist, queue_size=10)

        # Create a subscriber with the specified topic and message type, and specify the callback function
        rospy.Subscriber(self.camera_topic, Image, self.camera_callback)

    def camera_callback(self, msg):
        # This callback function will be called whenever a new image is received
        # Do something with the camera data here

        if msg != None:
            pass
        else:
            rospy.loginfo("none_data")

        
        frame = self.cvBridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
        frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경
        results = self.hands.process(image)  # 이미지에서 손을 찾고 결과를 반환
        
        if results.multi_hand_landmarks:  # 손이 인식되었는지 확인
            for hand_landmarks in results.multi_hand_landmarks:  # 반복문을 활용해 인식된 손의 주요 부분을 그림으로 그려 표현
                self.mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing_styles.get_default_hand_landmarks_style(),
                    self.mp_drawing_styles.get_default_hand_connections_style(),
                )

                points = hand_landmarks.landmark  #  landmark 좌표 정보들을 points라는 변수로 활용

                # 엄지손가락부터 새끼손가락까지 손가락이 펴졌는지 확인하고 이미지에 출력한다.
                # 엄지손가락 확인하기
                if self.distance(points[4], points[9]) < self.distance(points[3], points[9]):
                    fingers = "0"  # 접혔으면 0
                    rospy.loginfo("접힘")

                    rospy.loginfo("go straight")
                    linear_vel = 0.1

                else:
                    fingers = "1"  # 펴졌으면 1
                    rospy.loginfo("펴짐")

                    rospy.loginfo("stop")
                    linear_vel = 0.0
                
                self.twist.linear.x = linear_vel; self.twist.linear.y = 0.0; self.twist.linear.z = 0.0
                self.twist.angular.x = 0.0; self.twist.angular.y = 0.0; self.twist.angular.z = 0.0
                
                self.pub.publish(self.twist)

                cv2.putText(  # 0 또는 1을 이미지에 출력한다.
                    frame,
                    fingers,
                    (int(points[4].x * frame.shape[1]), int(points[4].y * frame.shape[0])),
                    cv2.FONT_HERSHEY_COMPLEX,
                    1,
                    (0, 255, 0),
                    5,
                )

                # 나머지 손가락 확인하기
                for i in range(8, 21, 4):
                    if self.distance(points[i], points[0]) < self.distance(points[i - 1], points[0]):
                        fingers = "0"  # 접혔으면 0
                    else:
                        fingers = "1"  # 펴졌으면 1
                    cv2.putText(  # 0 또는 1을 이미지에 출력한다.
                        frame,
                        fingers,
                        (int(points[i].x * frame.shape[1]), int(points[i].y * frame.shape[0])),
                        cv2.FONT_HERSHEY_COMPLEX,
                        1,
                        (0, 255, 0),
                        5,
                    )
        else:   
            pass

        cv2.imshow("hands", frame)  # 영상을 화면에 출력.

        key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기
        if key == 27:  # ESC를 눌렀을 경우
            cv2.destroyAllWindows()
    

    # 거리 계산 함수 선언
    def distance(self, p1, p2):
        return math.dist((p1.x, p1.y), (p2.x, p2.y))  # 두 점 p1, p2의 x, y 좌표로 거리를 계산한다.

        

    def run(self):
        # Spin to keep the script from exiting
        rospy.spin()

if __name__ == '__main__':
    # Replace '/camera/image_raw' with your actual camera topic
    camera_topic = '/camera/image'
    
    # Create an instance of the CameraSubscriber class
    camera_subscriber = CameraSubscriber(camera_topic)

    # Run the subscriber
    camera_subscriber.run()
