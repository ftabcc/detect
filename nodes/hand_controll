#!/usr/bin/env python3

import rospy

from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Twist
from sensor_msgs.msg import Image

import cv2  
import sys 
import mediapipe as mp 
import math
import numpy as np

class HandControll():
    def __init__(self):
        rospy.Subscriber('/camera/image', Image, self.direction)
        
        self.cvBridge = CvBridge()

        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        self.mp_hands = mp.solutions.hands  # object for hand detection
        self.max_num_hands = 1
        self.hands = self.mp_hands.Hands(max_num_hands=self.max_num_hands,
                                        min_detection_confidence=0.5,
                                        min_tracking_confidence=0.5)
        
        # For teleop
        self.twist = Twist()
        self.pub = rospy.Publisher('cmd_vel', Twist, queue_size=10)

        self.linear_vel = 0
        self.angular_vel = 0

    def direction(self, image):

        if image != None:
            pass
        else:
            rospy.loginfo("fail to get image data")

        frame = self.cvBridge.imgmsg_to_cv2(image, desired_encoding="bgr8")  
        frame = cv2.flip(frame, 1)  # flip left &right
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # convert color for mediapipe

        results = self.hands.process(image)  # result about detection

        if results.multi_hand_landmarks:  # hand detection is true
            for hand_landmarks in results.multi_hand_landmarks:  # draw joint points
                self.mp_drawing.draw_landmarks(
                    frame,
                    hand_landmarks,
                    self.mp_hands.HAND_CONNECTIONS,
                    self.mp_drawing_styles.get_default_hand_landmarks_style(),
                    self.mp_drawing_styles.get_default_hand_connections_style(),
                )
                joint = np.array([[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks.landmark])

                # Compute angles between joints
                joint_s = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:] # start joint
                joint_e = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:] # end joint
                vector = joint_s - joint_e # shape: (20,3)

                # Normalize vector for angle
                scale = np.linalg.norm(vector, axis=1)[:, np.newaxis] # shape: (20,1)
                unit_v = vector / scale

                # Get angle using arcos of dot product
                angle = np.arccos(np.einsum('ij,ij->i',
                    unit_v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], 
                    unit_v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:])) # shape: (15,)
                
                angle = np.degrees(angle) # Convert radian to degrees


                if np.mean(angle) < 50:
                    direction = vector[8][0]
                    hand_size = np.linalg.norm(joint[4]-joint[20])
                    self.linear_vel = 0.05/hand_size

                    if -0.1 <= direction <= 0.1:
                        self.angular_vel = 0.0
                        rospy.loginfo("go straight: {}".format(self.linear_vel))

                    else:
                        self.angular_vel = direction
                        rospy.loginfo("turn: {}".format(direction))

                else:
                    rospy.loginfo("stop")
                    self.linear_vel = 0
                
                self.twist.linear.x = self.linear_vel/5
                self.twist.angular.z = self.angular_vel*2

                self.pub.publish(self.twist)

        cv2.imshow("hands", frame)  
        key = cv2.waitKey(5) & 0xFF  
        if key == 27:  # ESC key
            cv2.destroyAllWindows()

    def main(self):
        rospy.spin()

if __name__ == '__main__':
    rospy.init_node('HandControll')
    node = HandControll()
    node.main()
